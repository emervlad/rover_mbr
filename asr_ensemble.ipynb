{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cb18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sentencepiece\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "from tqdm.auto import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "from src.models import ConformerLAS, ConformerCTC\n",
    "from src.metrics import WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "28bb692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model: pl.LightningModule, ckpt_path: str) -> pl.LightningModule:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    wer = WER()\n",
    "    wer.update(refs, hyps)\n",
    "    return wer.compute()[0].item()\n",
    "\n",
    "\n",
    "class GreedyDecoderLAS:\n",
    "    def __init__(self, model: ConformerLAS, max_steps=20):\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def __call__(self, encoded: torch.Tensor, ent: torch.Tensor = None) -> str:\n",
    "        \n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "        \n",
    "        for _ in range(self.max_steps):\n",
    "            \n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "        \n",
    "            best_next_token = distribution[0, -1].argmax()\n",
    "\n",
    "            \n",
    "            if best_next_token == self.model.decoder.tokenizer.eos_id():\n",
    "                break\n",
    "\n",
    "            tokens.append(best_next_token.item())\n",
    "\n",
    "        return self.model.decoder.tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7489a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6bd256ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'test_opus/farfield/manifest.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d7a33",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "91eff477",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_las.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "conf.model.decoder.tokenizer = \"./data/tokenizer/bpe_1024_bos_eos.model\"\n",
    "\n",
    "conformer_las = init_model(\n",
    "    model=ConformerLAS(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_las_2epochs.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a31fd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92baf710c794e288855d07add5064db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "las_decoder = GreedyDecoderLAS(conformer_las)\n",
    "\n",
    "refs, hyps_las = [], []\n",
    "\n",
    "for batch in tqdm(conformer_las.val_dataloader()):\n",
    "\n",
    "    features, features_len, targets, target_len = batch\n",
    "\n",
    "    encoded, encoded_len = conformer_las(features, features_len)\n",
    "    \n",
    "    for i in range(features.shape[0]):\n",
    "\n",
    "        encoder_states = encoded[[i], :encoded_len[i], :]\n",
    "\n",
    "        ref_tokens = targets[i, :target_len[i]].tolist()\n",
    "\n",
    "        refs.append(\n",
    "            conformer_las.decoder.tokenizer.decode(ref_tokens)\n",
    "        )\n",
    "        hyps_las.append(\n",
    "            las_decoder(encoder_states)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d05af7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42290276288986206"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wer(refs, hyps_las)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262680b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ddf4b47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: load models, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "355b4368",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decode_ctc_hyps(model: ConformerCTC) -> Tuple[List[str], List[str]]:\n",
    "    \n",
    "    refs, hyps_ctc = [], []\n",
    "\n",
    "    for batch in tqdm(model.val_dataloader()):\n",
    "\n",
    "        features, features_len, targets, target_len = batch\n",
    "\n",
    "        encoded, encoded_len, preds = model(features, features_len)\n",
    "\n",
    "        refs.extend(\n",
    "            model.decoder.decode(targets, target_len, unique_consecutive=True)\n",
    "        )\n",
    "        hyps_ctc.extend(\n",
    "            model.decoder.decode(preds, encoded_len, unique_consecutive=True)\n",
    "        )\n",
    "\n",
    "    return refs, hyps_ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2430e1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ca5cae49f44d618c418e7369b8c4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc = decode_ctc_hyps(conformer_ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c10e7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.431997150182724"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wer(refs, hyps_ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64281db5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f91dfc832e545909e8de82d26b11b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc_wide.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc_wide = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_wide_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc_wide = decode_ctc_hyps(conformer_ctc_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bdda104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38093534111976624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wer(refs, hyps_ctc_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba5e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c13f9f3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ROVER: Recognizer Output Voting Error Reduction — 5 points\n",
    "\n",
    "* [A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)](https://ieeexplore.ieee.org/document/659110)\n",
    "* [Improved ROVER using Language Model Information](https://www-tlp.limsi.fr/public/asr00_holger.pdf)\n",
    "\n",
    "Alignment + Voting\n",
    "\n",
    "![](./images/rover_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f60776f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from crowdkit.aggregation.texts import ROVER"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "167e04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: aggregate hypotheses, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5480795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поскольку мы не меняли dataloader, а случайности в нём нет, то все 3 refs имеют одинаковый порядок\n",
    "# Поскольку GroupBy в fit_predict возвращает значения в порядке оригинального ДатаФрейма, то для выравнивания\n",
    "# достаточно вставлять модели от меньшего wer'a к большему\n",
    "data = {\"task\": list(range(len(refs))) * 3, \"text\": hyps_ctc_wide + hyps_las + hyps_ctc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "72d74139",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "59efe52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda s: s.lower())\n",
    "tokenizer = lambda s: s.split(' ')\n",
    "detokenizer = lambda tokens: ' '.join(tokens)\n",
    "result = pd.DataFrame(data=ROVER(tokenizer, detokenizer).fit_predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "12d69158",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result.index) == list(range(len(refs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ab7c7ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyps_rover = list(result['agg_text'])\n",
    "compute_wer(refs, hyps_rover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca3042",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MBR: Minimum Bayes Risk — 5 points\n",
    "\n",
    "\n",
    "* [Minimum Bayes Risk Decoding and System\n",
    "Combination Based on a Recursion for Edit Distance](https://danielpovey.com/files/csl11_consensus.pdf)\n",
    "* [mbr-decoding blog-post](https://suzyahyah.github.io/bayesian%20inference/machine%20translation/2022/02/15/mbr-decoding.html)\n",
    "* [Combination of end-to-end and hybrid models for speech recognition](http://www.interspeech2020.org/uploadfile/pdf/Tue-1-8-4.pdf)\n",
    "\n",
    "![](./images/mbr_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd329aa4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# TODO: retrieve minimum-Distance hypothesis, estimate WER"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6e63d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EstimationLAS:\n",
    "    def __init__(self, model: ConformerLAS, max_steps=20):\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def __call__(self, encoded: torch.Tensor, est: torch.Tensor) -> str:\n",
    "        \n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "        \n",
    "        inds = self.model.decoder.tokenizer.encode(est)\n",
    "        \n",
    "        prob = 0\n",
    "\n",
    "        for i in range(self.max_steps):\n",
    "            \n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "            if (i == len(inds)):\n",
    "                break\n",
    "            prob += distribution[0, -1][inds[i]]\n",
    "            \n",
    "            best_next_token = inds[i]\n",
    "            \n",
    "            if best_next_token == self.model.decoder.tokenizer.eos_id():\n",
    "                break\n",
    "\n",
    "            tokens.append(best_next_token)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "762cf1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_estimator = EstimationLAS(conformer_las)\n",
    "\n",
    "las_estimate_las, las_estimate_ctc, las_estimate_ctc_wide = [], [], []\n",
    "\n",
    "j = 0\n",
    "\n",
    "for batch in tqdm(conformer_las.val_dataloader()):\n",
    "\n",
    "    features, features_len, targets, target_len = batch\n",
    "\n",
    "    encoded, encoded_len = conformer_las(features, features_len)\n",
    "    \n",
    "    for i in range(features.shape[0]):\n",
    "\n",
    "        encoder_states = encoded[[i], :encoded_len[i], :]\n",
    "\n",
    "        las_estimate_las.append(las_estimator(encoder_states, hyps_las[j]))\n",
    "        las_estimate_ctc.append(las_estimator(encoder_states, hyps_ctc[j]))\n",
    "        las_estimate_ctc_wide.append(las_estimator(encoder_states, hyps_ctc_wide[j]))\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cf1c14ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ca2748cd1345afa5c7d93368595f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, st in enumerate(hyps_las):\n",
    "    for ss in st:\n",
    "        if ss not in conformer_ctc.decoder.labels:\n",
    "            print(refs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c7111d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_inds = {conformer_ctc.decoder.labels[i]: i for i in range(len(conformer_ctc.decoder.labels))}\n",
    "tokens_to_inds['⁇'] = tokens_to_inds['ъ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a69543eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20093945720250522"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ctc_estimate_hyp(model: ConformerCTC, hyps_las, hyps_ctc, hyps_ctc_wide) -> Tuple[List[str], List[str]]:\n",
    "    \n",
    "    j = 0\n",
    "    \n",
    "    model_estimate_ctc, model_estimate_las, model_estimate_ctc_wide = [], [], []\n",
    "    \n",
    "    ctc_loss = torch.nn.CTCLoss(blank=model.decoder.blank_id)\n",
    "    \n",
    "    for batch in tqdm(model.val_dataloader()):\n",
    "\n",
    "        features, features_len, targets, target_len = batch\n",
    "\n",
    "        encoded, encoded_len, preds = model(features, features_len)\n",
    "        \n",
    "        for i in range(features.shape[0]):\n",
    "            \n",
    "            inds_las = torch.Tensor([tokens_to_inds[char] for char in hyps_las[j]])\n",
    "            inds_ctc = torch.Tensor([tokens_to_inds[char] for char in hyps_ctc[j]])\n",
    "            inds_ctc_wide = torch.Tensor([tokens_to_inds[char] for char in hyps_ctc_wide[j]])\n",
    "\n",
    "            model_estimate_las.append(ctc_loss(encoded[i], inds_las, \\\n",
    "                                               torch.IntTensor([encoded_len[0]]), torch.IntTensor([len(inds_las)])))\n",
    "            model_estimate_ctc.append(ctc_loss(encoded[i], inds_ctc,\\\n",
    "                                               torch.IntTensor([encoded_len[0]]), torch.IntTensor([len(inds_ctc)])))\n",
    "            model_estimate_ctc_wide.append(ctc_loss(encoded[i], inds_ctc_wide,\\\n",
    "                                                    torch.IntTensor([encoded_len[0]]), \\\n",
    "                                                    torch.IntTensor([len(inds_ctc_wide)])))\n",
    "            \n",
    "            j += 1\n",
    "\n",
    "    return model_estimate_las, model_estimate_ctc, model_estimate_ctc_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f45f2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_estimate_las, ctc_estimate_ctc, ctc_estimate_ctc_wide = \\\n",
    "ctc_estimate_hyp(conformer_ctc, hyps_las, hyps_ctc, hyps_ctc_wide)\n",
    "\n",
    "ctc_wide_estimate_las, ctc_wide_estimate_ctc, ctc_wide_estimate_ctc_wide = \\\n",
    "ctc_estimate_hyp(conformer_ctc_wide, hyps_las, hyps_ctc, hyps_ctc_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a43283f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps_mbr = []\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "las_prob = F.normalize((torch.Tensor([las_estimate_las, las_estimate_ctc, las_estimate_ctc_wide])), p=1.0, dim=0)\n",
    "ctc_prob = softmax(-torch.Tensor([ctc_estimate_las, ctc_estimate_ctc, ctc_estimate_ctc_wide]))\n",
    "ctc_wide_prob = softmax(-torch.Tensor([ctc_wide_estimate_las, ctc_wide_estimate_ctc, ctc_wide_estimate_ctc_wide]))\n",
    "\n",
    "for i in range(len(refs)):\n",
    "    w = [hyps_las[i].split(' '), hyps_ctc[i].split(' '), hyps_ctc_wide[i].split(' ')]\n",
    "    w_las = sum([editdistance.eval(w[0], w[j]) * las_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[0], w[j]) * ctc_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[0], w[j]) * ctc_wide_prob[j, i] for j in range(3)])\n",
    "    w_ctc = sum([editdistance.eval(w[1], w[j]) * las_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[1], w[j]) * ctc_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[1], w[j]) * ctc_wide_prob[j, i] for j in range(3)])\n",
    "    w_ctc_wide = sum([editdistance.eval(w[2], w[j]) * las_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[2], w[j]) * ctc_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[2], w[j]) * ctc_wide_prob[j, i] for j in range(3)])\n",
    "    hyps_mbr.append(' '.join(w[torch.argmin(torch.Tensor([w_las, w_ctc, w_ctc_wide]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "16893463",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_wer(refs, hyps_mbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b892c3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27244258872651356"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "26cfc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps_mbr = []\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "las_prob = torch.nn.functional.normalize(torch.Tensor([las_estimate_las, las_estimate_ctc, las_estimate_ctc_wide]), p=1.0, dim=0)\n",
    "ctc_prob = softmax(-torch.Tensor([ctc_estimate_las, ctc_estimate_ctc, ctc_estimate_ctc_wide]))\n",
    "ctc_wide_prob = softmax(-torch.Tensor([ctc_wide_estimate_las, ctc_wide_estimate_ctc, ctc_wide_estimate_ctc_wide]))\n",
    "\n",
    "for i in range(len(refs)):\n",
    "    w = [hyps_las[i].split(' '), hyps_ctc[i].split(' '), hyps_ctc_wide[i].split(' ')]\n",
    "    w_las = sum([editdistance.eval(w[0], w[j]) * las_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[0], w[j]) * ctc_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[0], w[j]) * ctc_wide_prob[j, i] for j in range(3)])\n",
    "    w_ctc = sum([editdistance.eval(w[1], w[j]) * las_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[1], w[j]) * ctc_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[1], w[j]) * ctc_wide_prob[j, i] for j in range(3)])\n",
    "    w_ctc_wide = sum([editdistance.eval(w[2], w[j]) * las_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[2], w[j]) * ctc_prob[j, i] for j in range(3)]) + \\\n",
    "        sum([editdistance.eval(w[2], w[j]) * ctc_wide_prob[j, i] for j in range(3)])\n",
    "    hyps_mbr.append(' '.join(w[torch.argmin(torch.Tensor([w_las, w_ctc, w_ctc_wide]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d7c9cec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3568875193595886"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wer(refs, hyps_mbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "9cf13fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAS</th>\n",
       "      <th>CTC</th>\n",
       "      <th>CTC Wide</th>\n",
       "      <th>ROVER</th>\n",
       "      <th>MBR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.422903</td>\n",
       "      <td>0.425405</td>\n",
       "      <td>0.370949</td>\n",
       "      <td>0.359509</td>\n",
       "      <td>0.356888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LAS       CTC  CTC Wide     ROVER       MBR\n",
       "0  0.422903  0.425405  0.370949  0.359509  0.356888"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"LAS\": compute_wer(refs, hyps_las), \"CTC\": compute_wer(refs, hyps_ctc), \\\n",
    "             \"CTC Wide\": compute_wer(refs, hyps_ctc_wide), \"ROVER\": compute_wer(refs, hyps_rover), \\\n",
    "             \"MBR\": compute_wer(refs, hyps_mbr)}, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545d5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}